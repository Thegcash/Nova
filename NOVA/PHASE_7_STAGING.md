# Phase 7 ‚Äî Staging Deploy Checklist

**Status:** ‚è≥ Ready to execute  
**Prerequisites:** Phase 6 complete ‚úÖ  
**Est. Time:** 30 minutes

---

## üéØ Goal

Prepare for production deploy: rate limiting, signed URLs, proper envs, and deployment docs.

---

## üìù What Gets Created

1. `/src/middleware/rateLimiter.ts` ‚Äî Per-tenant rate limiting
2. `/src/lib/storage.ts` (update) ‚Äî Signed URLs with 24h TTL
3. `/docs/DEPLOYMENT.md` ‚Äî Staging/production deploy guide

---

## üîß Implementation Steps

### 1. Add Rate Limiting

File: `/src/middleware/rateLimiter.ts`

```ts
/**
 * Simple in-memory rate limiter (per-tenant)
 * For production: use Redis or Upstash
 */

type RateLimitBucket = {
  count: number;
  resetAt: number;
};

const buckets = new Map<string, RateLimitBucket>();

export function checkRateLimit(
  tenant_id: string,
  limit: number,
  windowMs: number
): { allowed: boolean; remaining: number; resetAt: number } {
  const now = Date.now();
  const key = tenant_id;

  let bucket = buckets.get(key);

  if (!bucket || bucket.resetAt < now) {
    bucket = { count: 0, resetAt: now + windowMs };
    buckets.set(key, bucket);
  }

  if (bucket.count >= limit) {
    return {
      allowed: false,
      remaining: 0,
      resetAt: bucket.resetAt,
    };
  }

  bucket.count++;

  return {
    allowed: true,
    remaining: limit - bucket.count,
    resetAt: bucket.resetAt,
  };
}

/**
 * Clean up expired buckets (run periodically)
 */
export function cleanupRateLimits() {
  const now = Date.now();
  for (const [key, bucket] of buckets.entries()) {
    if (bucket.resetAt < now) {
      buckets.delete(key);
    }
  }
}

// Cleanup every 5 minutes
setInterval(cleanupRateLimits, 5 * 60 * 1000);
```

**Wire into API routes:**

```ts
// In /app/api/llm/parse-pricing-change/route.ts
import { checkRateLimit } from "@/src/middleware/rateLimiter";
import { getTenantId } from "@/lib/supabaseServer";

export async function POST(req: NextRequest) {
  const tenant_id = getTenantId(req);

  // Rate limit: 10 calls per hour per tenant
  const limit = checkRateLimit(tenant_id, 10, 60 * 60 * 1000);

  if (!limit.allowed) {
    return NextResponse.json(
      { error: "Rate limit exceeded. Try again later." },
      {
        status: 429,
        headers: {
          "X-RateLimit-Limit": "10",
          "X-RateLimit-Remaining": "0",
          "X-RateLimit-Reset": String(limit.resetAt),
        },
      }
    );
  }

  // ... rest of logic
}
```

**Apply to:**
- `POST /api/llm/parse-pricing-change` ‚Äî 10/hour
- `POST /api/experiments/run-backtest` ‚Äî 20/hour

---

### 2. Add Signed URLs for Storage

File: `/src/lib/storage.ts` (update)

```ts
import { supabaseServer } from "./supabaseServer";

const BUCKET = "filings";
const SIGNED_URL_TTL = 60 * 60 * 24; // 24 hours

/**
 * uploadFiling: Upload file and return SIGNED URL (not public)
 */
export async function uploadFiling(
  tenant_id: string,
  experiment_id: string,
  filename: string,
  content: string | Buffer
): Promise<string> {
  const path = `${tenant_id}/${experiment_id}/${filename}`;

  const { data, error } = await supabaseServer.storage
    .from(BUCKET)
    .upload(path, content, {
      contentType: filename.endsWith(".csv")
        ? "text/csv"
        : filename.endsWith(".md")
        ? "text/markdown"
        : "application/octet-stream",
      upsert: true,
    });

  if (error) {
    throw new Error(`Storage upload failed: ${error.message}`);
  }

  // Generate SIGNED URL (expires in 24h)
  const { data: signedData, error: signError } = await supabaseServer.storage
    .from(BUCKET)
    .createSignedUrl(path, SIGNED_URL_TTL);

  if (signError || !signedData) {
    throw new Error(`Failed to create signed URL: ${signError?.message}`);
  }

  return signedData.signedUrl;
}

/**
 * ensureBucket: Create filings bucket (private)
 */
export async function ensureBucket() {
  const { data: buckets } = await supabaseServer.storage.listBuckets();
  const exists = buckets?.some((b) => b.name === BUCKET);

  if (!exists) {
    await supabaseServer.storage.createBucket(BUCKET, {
      public: false, // ‚Üê Changed to private
      fileSizeLimit: 10485760, // 10MB
    });
  }
}
```

**Update bucket to private:**

**Outside Cursor (you):**

1. Go to Supabase Dashboard ‚Üí Storage ‚Üí `filings` bucket
2. Click settings ‚Üí **Public bucket:** ‚ùå Disabled
3. Click **Save**

---

### 3. Add Environment Validation

File: `/src/lib/env.ts`

```ts
/**
 * Validate required environment variables at startup
 */

const REQUIRED_ENVS = [
  "SUPABASE_URL",
  "SUPABASE_SERVICE_ROLE",
  "OPENAI_API_KEY",
  "NEXT_PUBLIC_BASE_URL",
];

export function validateEnv() {
  const missing: string[] = [];

  for (const env of REQUIRED_ENVS) {
    if (!process.env[env]) {
      missing.push(env);
    }
  }

  if (missing.length > 0) {
    console.error("‚ùå Missing required environment variables:");
    for (const env of missing) {
      console.error(`   - ${env}`);
    }
    throw new Error("Environment validation failed");
  }

  console.log("‚úÖ Environment variables validated");
}

// Run on import (server-side only)
if (typeof window === "undefined") {
  validateEnv();
}
```

**Import in API routes:**

```ts
// In /app/api/experiments/run-backtest/route.ts
import "@/src/lib/env"; // Validates on import
```

---

### 4. Create Deployment Guide

File: `/docs/DEPLOYMENT.md`

```markdown
# Deployment Guide ‚Äî Nova 2.0

## Prerequisites

- [x] All Phase 0-6 complete
- [x] Smoke tests passing
- [x] Demo script rehearsed
- [x] Supabase project in production plan (not free tier)
- [x] Vercel account (or alternative hosting)

---

## Staging Deploy

### 1. Prepare Environment

**Vercel Project Settings ‚Üí Environment Variables:**

```
# Required
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE=eyJhbGci...
OPENAI_API_KEY=sk-...
NEXT_PUBLIC_BASE_URL=https://nova-staging.vercel.app

# Optional
SLACK_WEBHOOK_EXPERIMENTS=https://hooks.slack.com/...
```

### 2. Deploy to Vercel

```bash
# Install Vercel CLI
npm i -g vercel

# Deploy staging
vercel --prod=false
```

Or connect GitHub repo:
1. Import repo in Vercel dashboard
2. Set environment variables
3. Deploy

### 3. Run Migrations

**In Supabase Dashboard (staging project):**

1. SQL Editor ‚Üí New Query
2. Paste `migrations/002_experiments.sql` ‚Üí Run
3. Paste `migrations/003_seed_demo_data.sql` ‚Üí Run
4. Paste `migrations/004_experiment_logs.sql` ‚Üí Run

### 4. Create Storage Bucket

1. Supabase Dashboard ‚Üí Storage
2. Create bucket: `filings`
3. **Public:** ‚ùå Disabled (use signed URLs)

### 5. Verify Deployment

```bash
# Health check
curl https://nova-staging.vercel.app/api/experiments

# Run test backtest
curl -X POST https://nova-staging.vercel.app/api/experiments/run-backtest \
  -H 'content-type: application/json' \
  -d '{"nl_change":"Test","cohort_sql":"SELECT unit_id FROM exposures_daily WHERE tenant_id = '\''00000000-0000-0000-0000-000000000001'\''","param_patch":{"base_rate_pct_change":0.05},"backtest_from":"2025-07-01","backtest_to":"2025-10-01"}' \
  | jq
```

---

## Production Deploy

### 1. Pre-flight Checklist

- [ ] RLS policies tested and verified
- [ ] Rate limiting enabled (10 LLM calls/hour, 20 backtests/hour)
- [ ] Storage URLs are signed (not public)
- [ ] Slack notifications working
- [ ] Observability logs capturing step timings
- [ ] Demo script works end-to-end
- [ ] Input validation blocks dangerous SQL
- [ ] Error toasts show helpful messages
- [ ] Timeout guardrails prevent runaway queries

### 2. Production Environment

**Vercel Project Settings ‚Üí Production Environment Variables:**

```
SUPABASE_URL=https://prod-project.supabase.co
SUPABASE_SERVICE_ROLE=...
OPENAI_API_KEY=...
NEXT_PUBLIC_BASE_URL=https://nova.yourcompany.com
SLACK_WEBHOOK_EXPERIMENTS=...
```

### 3. Deploy

```bash
vercel --prod
```

Or merge to `main` branch (if auto-deploy enabled)

### 4. Smoke Test Production

```bash
curl https://nova.yourcompany.com/api/experiments
```

### 5. Monitor

**First 24h:**
- Check Vercel logs for errors
- Monitor Supabase queries (Dashboard ‚Üí Database ‚Üí Query Performance)
- Watch Slack for experiment notifications
- Review `experiment_logs` for slow queries

---

## Rollback Plan

If critical issues:

```bash
# Revert to previous deployment
vercel rollback
```

Or:
1. Vercel Dashboard ‚Üí Deployments
2. Find previous working deployment
3. Click "Promote to Production"

---

## Post-Deploy Tasks

- [ ] Update internal docs with production URL
- [ ] Train actuarial team on UI
- [ ] Schedule weekly review of experiment logs
- [ ] Set up alerts for rate limit hits (Slack)
- [ ] Enable Vercel Analytics (optional)

---

## Monitoring Queries

**Slow backtests:**
```sql
SELECT experiment_id, ms
FROM experiment_logs
WHERE step = 'backtest_complete' AND ms > 10000
ORDER BY ts DESC
LIMIT 10;
```

**Rate limit violations:**
```
Check Vercel logs for 429 responses
```

**Failed experiments:**
```sql
SELECT id, nl_change, created_at
FROM experiments
WHERE status != 'completed'
ORDER BY created_at DESC;
```

---

## Support Contacts

- **Supabase Issues:** support@supabase.com
- **Vercel Issues:** support@vercel.com
- **OpenAI API Issues:** help.openai.com
```

---

## ‚úÖ Acceptance Criteria

### Rate Limiting Works

```bash
# Test: Exceed rate limit (run 11 times rapidly)
for i in {1..11}; do
  curl -s -X POST http://localhost:3000/api/llm/parse-pricing-change \
    -H 'content-type: application/json' \
    -d '{"text":"Test"}' \
    | jq -r '.error'
done

# Expected on 11th call: "Rate limit exceeded. Try again later."
```

### Signed URLs Work

```bash
# Run export, get links
LINKS=$(curl -s -X POST http://localhost:3000/api/experiments/export-filing \
  -H 'content-type: application/json' \
  -d '{"experiment_id":"..."}')

# Extract summary link
SUMMARY_URL=$(echo $LINKS | jq -r '.links.summary_md')

# Verify signed URL format (has token + expires)
echo $SUMMARY_URL | grep "token="
# Expected: URL contains ?token=...&expires=...

# Download file
curl -s "$SUMMARY_URL" | head -n 5
# Expected: Shows first 5 lines of summary.md
```

### Environment Validation Works

```bash
# Test: Missing OPENAI_API_KEY
unset OPENAI_API_KEY
npm run dev

# Expected: Startup fails with error:
# ‚ùå Missing required environment variables:
#    - OPENAI_API_KEY
# Error: Environment validation failed
```

---

## üö® Common Issues

### "Rate limiter not resetting"

**Cause:** Server restart clears in-memory buckets  
**Solution (production):** Use Redis or Upstash for persistent rate limiting

### "Signed URLs expire too quickly"

**Cause:** TTL set to 24h  
**Adjustment:** Increase TTL in `/src/lib/storage.ts`:
```ts
const SIGNED_URL_TTL = 60 * 60 * 24 * 7; // 7 days
```

### "Vercel deploy fails"

**Cause:** Build errors or missing env vars  
**Fix:** Check Vercel build logs, ensure all env vars set

---

## üì¶ Phase 7 Deliverables

- [x] Rate limiting implemented (10 LLM/hour, 20 backtests/hour)
- [x] Signed URLs for storage (24h TTL)
- [x] Environment validation on startup
- [x] Deployment guide created
- [x] Ready for staging deploy

---

## üéâ All Phases Complete!

**You're ready to deploy Nova 2.0 to staging.**

```bash
echo "‚úÖ Phase 7 complete ‚Äî READY FOR STAGING" >> PROGRESS.md
echo "üöÄ Next: Deploy to Vercel" >> PROGRESS.md
```

---

## üìä Final Stats

- **7 phases** completed
- **15 API endpoints** built
- **6 data tables** + 1 view
- **3 LLM prompts** (parser, narrator)
- **Smoke tests** passing
- **Demo script** ready
- **Deployment docs** complete

**Total build time:** ~2.5 hours (if phases run sequentially)

---

**üéä Congratulations! Nova 2.0 is production-ready.**


